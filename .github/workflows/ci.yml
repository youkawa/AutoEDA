name: ci
on: [push, pull_request]
jobs:
  web:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      - run: npm ci || npm i
      - run: npm run lint:web
      - run: npm run typecheck:web
      - run: npm run test:web
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install API Python deps
        run: python -m pip install --upgrade pip && pip install -r apps/api/requirements.txt
      - name: Dump OpenAPI (without server)
        run: npm run schema:dump:openapi
      - name: Compare OpenAPI snapshot (schemas only)
        continue-on-error: true
        run: |
          python - << 'PY'
          import json, sys
          from pathlib import Path
          cur = json.loads(Path('dist/openapi.json').read_text())
          base = json.loads(Path('docs/api/openapi.snapshot.json').read_text())
          def pick(x):
            return { 'openapi': x.get('openapi'), 'components': { 'schemas': x.get('components',{}).get('schemas',{}) } }
          if pick(cur) != pick(base):
            print('[openapi-diff] snapshot differs from generated spec. Update docs/api/openapi.snapshot.json in this PR.')
            # non-blocking: enforced by strict schema checks below
            sys.exit(0)
          print('[openapi-diff] no changes')
          PY
      - name: Validate Zod vs OpenAPI
        run: npm run schema:validate
      - name: Check OpenAPI components
        run: python3 apps/api/scripts/check_openapi.py
      - name: Check OpenAPI paths and responses
        run: python3 apps/api/scripts/check_openapi_paths.py
      - name: Check OpenAPI compatibility (ChartJob.error_code)
        id: openapi_compat
        run: npm run schema:check:openapi-compat
        continue-on-error: true
      - name: Comment OpenAPI compat result
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const outcome = `${{ steps.openapi_compat.outcome }}`;
            const ok = outcome === 'success';
            const body = ok
              ? `✅ OpenAPI compat check passed (ChartJob.error_code).`
              : `❌ OpenAPI compat check failed. Please review ChartJob.error_code enum or schema.`;
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });
      - name: Save OpenAPI compat result
        if: always()
        run: |
          mkdir -p reports
          echo "${{ steps.openapi_compat.outcome }}" > reports/openapi_compat.txt
          TS=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "# OpenAPI Compatibility\n\n- Time: $TS\n- Outcome: ${{ steps.openapi_compat.outcome }}\n- Target: ChartJob.error_code enum\n\nIf failed, please check schema changes and the 'openapi-compat' artifact." > reports/openapi_compat_summary.md
      - name: Upload OpenAPI compat artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: openapi-compat
          path: |
            reports/openapi_compat.txt
            reports/openapi_compat_summary.md
          if-no-files-found: warn
      - name: Update PR body with OpenAPI compat summary (on failure)
        if: always() && github.event_name == 'pull_request' && steps.openapi_compat.outcome != 'success'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('reports/openapi_compat_summary.md', 'utf8');
            let table = '';
            let destructive = 'unknown';
            try {
              const diff = JSON.parse(fs.readFileSync('reports/openapi_compat_diff.json', 'utf8'));
              const miss = diff.missing || [];
              const extra = diff.extra || [];
              table = '\n\n| Type | Values |\n|---|---|\n' +
                      `| Missing | ${miss.join(', ') || '-'} |\n` +
                      `| Extra | ${extra.join(', ') || '-'} |\n`;
              destructive = miss.length ? 'breaking' : (extra.length ? 'non-breaking' : 'unknown');
            } catch (e) { /* ignore */ }
            const guide = '\n\n**Migration Guide (suggested):**\n' +
              '- If values are Missing: add them back in server schema or relax enum, and update UI mapping.\n' +
              '- If values are Extra: extend client mapping (friendly messages) and document new codes.\n' +
              '- Ensure SDK exceptions carry `error_code` and UI shows human-readable text.';
            const { data: pr } = await github.rest.pulls.get({ owner: context.repo.owner, repo: context.repo.repo, pull_number: context.issue.number });
            const body = pr.body || '';
            const marker = '\n\n---\nOpenAPI Compatibility Summary:\n';
            const heading = `\n\n**Result:** ${destructive.toUpperCase()}`;
            const next = body.includes(marker) ? body.split(marker)[0] + marker + heading + '\n' + summary + table + guide : body + marker + heading + '\n' + summary + table + guide;
            await github.rest.pulls.update({ owner: context.repo.owner, repo: context.repo.repo, pull_number: context.issue.number, body: next });
            try {
              const label = destructive === 'breaking' ? 'openapi:breaking' : (destructive === 'non-breaking' ? 'openapi:non-breaking' : 'openapi:unknown');
              await github.rest.issues.addLabels({ owner: context.repo.owner, repo: context.repo.repo, issue_number: context.issue.number, labels: [label] });
            } catch (e) {}
      - name: Evaluate API NFR (p95 & thresholds)
        run: python3 apps/api/scripts/evaluate_nfr.py
      - name: Check SLO thresholds
        run: npm run check:slo
        env:
          AUTOEDA_SLO_OUTPUT: reports/slo_report.json
      - name: Check RAG golden queries
        run: npm run check:rag
        env:
          AUTOEDA_RAG_OUTPUT: reports/rag_report.json
      - name: Merge QA reports
        run: npm run report:merge
        env:
          AUTOEDA_SLO_OUTPUT: reports/slo_report.json
          AUTOEDA_RAG_OUTPUT: reports/rag_report.json
          AUTOEDA_QA_SUMMARY: reports/quality_summary.json
      - name: Upload QA reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa-reports
          path: reports
          if-no-files-found: ignore
      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report
          if-no-files-found: ignore
      - name: Install Playwright Browsers
        run: npx playwright install --with-deps
      - run: npx playwright test --reporter=line,html
      - name: Build Storybook static
        run: npm run storybook:build
      - name: Check Storybook snapshot presence (OS-specific)
        run: |
          OS_TAG=$(node -e "console.log(process.platform==='win32'?'windows':process.platform==='darwin'?'darwin':'linux')")
          if ls tests/storybook/*-snapshots/*-$OS_TAG.png 1> /dev/null 2>&1; then
            echo "SNAPSHOT_EXISTS=true" >> $GITHUB_ENV
          else
            echo "SNAPSHOT_EXISTS=false" >> $GITHUB_ENV
          fi
      - name: Storybook visual regression
        if: env.SNAPSHOT_EXISTS == 'true'
        run: npm run storybook:test
      - name: Storybook create baseline snapshots (first run)
        if: env.SNAPSHOT_EXISTS != 'true'
        run: npm run storybook:test -- --update-snapshots
        continue-on-error: true
      - name: Upload Storybook snapshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: storybook-snapshots
          path: tests/storybook/*-snapshots
          if-no-files-found: ignore
      - name: Upload Storybook visual report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: storybook-playwright-report
          path: test-results/storybook
          if-no-files-found: ignore
      - run: npm run build:web
